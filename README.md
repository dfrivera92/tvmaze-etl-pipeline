# ğŸ¬ TVMaze ETL Pipeline
![Python](https://img.shields.io/badge/Python-3.8%2B-blue?logo=python&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green)
![Workflow](https://img.shields.io/badge/Workflow-ETL_Pipeline-orange)
![Status](https://img.shields.io/badge/Status-Active-brightgreen)
## Overview
An automated ETL pipeline that extracts TV show data from TVMaze API, processes it through multiple stages, and loads it into a SQLite database.

## ğŸ—ï¸ Project structure
```plaintext
tvmaze-etl-pipeline/
â”œâ”€â”€ data/                  # Processed Parquet files
â”‚   â””â”€â”€ tvmaze_data_YYYY-MM.parquet
â”œâ”€â”€ model/                 # Image of the data model created to store the data
â”‚   â””â”€â”€ model_structure.png
â”œâ”€â”€ db/                    # SQLite database storage
â”‚   â””â”€â”€ tvmaze.db
â”œâ”€â”€ json/                  # Raw JSON data from TVMaze API
â”‚   â””â”€â”€ YYYY-MM-DD.json
â”œâ”€â”€ profiling/            # Data quality reports
â”‚   â””â”€â”€ data_profile_report.html
â””â”€â”€ src/                  # Source code
    â”œâ”€â”€ data_ingestion.py
    â”œâ”€â”€ data_processing.py
    â”œâ”€â”€ data_profiling.py
    â”œâ”€â”€ data_cleaning.py
    â”œâ”€â”€ data_export.py
    â”œâ”€â”€ data_normalization.py
    â”œâ”€â”€ db_loader.py
    â””â”€â”€ main.py
```

# Key features
-ğŸ“¡ **API Integration**: Fetches TV show data from TVMaze API for any specified month
- ğŸ§¹ **Data Cleaning**: Handles missing values, duplicates, and inconsistencies
- ğŸ“Š **Data Profiling**: Generates comprehensive quality reports with `ydata-profiling`
- ğŸš€ **Efficient Storage**: Uses Parquet format for processed data
- ğŸ—„ï¸ **Relational Model**: Normalizes data into efficient SQL tables
- âš™ï¸ **Modular Design**: Each component follows single responsibility principle

## âš™ï¸ Requirements
Install required packages
```
pip install -r requirements.txt
```

## ğŸš€ Usage
Run the ETL pipeline using:
`python3 src/main.py`
### ğŸ”„ Pipeline Workflow
The pipeline executes the following steps as shown in [`main.py`](/src/main.py):
1. Data Ingestion: [`TVMazeDataFetcher`](/src/data_ingestion.py) fetches show data from TVMaze API
2. Data Processing: [`TVMazeDataProcessor`](/src/data_processing.py) converts JSON files to DataFrame
3. Data Profiling: [`TVMazeDataProfiler`](/src/data_profiling.py) generates quality reports
4. Data Cleaning: [`TVMazeDataCleaner`](/src/data_cleaning.py) handles data quality issues
5. Data Export: [`ParquetExporter`](/src/data_export.py) saves processed data as Parquet
6. Data Normalization: [`TVMazeDataNormalizer`](/src/data_normalization.py) creates relational tables
7. Database Loading: [`SQLiteDB`](/src/db_loader.py) loads data into SQLite

## ğŸ“‚ Sample data (January 2024)
The repository includes sample data from January 2024:
- ğŸ“„ **Raw API Data**:
  Raw API responses stored in [`/json/2024-01-*.json`](/json/)
- ğŸ”„ **Processed Dataset**:
  Cleaned and transformed data in [`/data/tvmaze_data_2024-01.parquet`](/data/tvmaze_data_2024-01.parquet) (Parquet format)
- ğŸ“Š **Data Profile**
  HTML profile generated with Pandas Profiling available at [`/profiling/data_profile_report.html`](/profiling/data_profile_report.html)

## ğŸ›  Development
The ETL pipeline is modular, with each component handling a specific transformation:
- Each class in [`src`](/src/) follows single responsibility principle
- Data validation at each transformation step
- Comprehensive data profiling with ydata_profiling
- Efficient storage using Parquet format

## ğŸ“œ License
This project is licensed under the terms of the [LICENSE](LICENSE) file included in the repository.
